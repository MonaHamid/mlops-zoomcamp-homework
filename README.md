âœ¨ MLOps Zoomcamp Homework â€“ Week 1 & 2 Recap
ğŸš€ Finished Week 1 & Week 2 of the MLOps Zoomcamp â€” and hereâ€™s what Iâ€™ve learned and built so far:

ğŸ“¦ Week 1: Project Structure + Linear Regression on NYC Yellow Taxi Data
ğŸ”§ Setup & Tools
Got hands-on with GitHub Codespaces â€” like VS Code but in the cloud ğŸ’»â˜ï¸

Learned how to structure a proper ML project with reusable scripts instead of tangled notebooks

Installed dependencies, created .venv, and used make commands for automation

ğŸ›» Dataset: NYC Yellow Cab Trips (Janâ€“Feb 2023)
Downloaded January & February 2023 Parquet trip data

Conducted basic EDA and noticed some extreme trip durations â±ï¸

Filtered the data to include only reasonable trips (1 to 60 minutes)

ğŸ§  Feature Engineering
Computed duration from timestamps and converted to minutes

Applied one-hot encoding to PULocationID and DOLocationID

Used DictVectorizer to transform categorical features

ğŸ“ˆ Modeling
Trained a baseline Linear Regression model

Achieved:

ğŸŸ¢ Train RMSE: ~7.64

ğŸ”µ Validation RMSE: ~7.81

Logged model performance and serialized the vectorizer + model

âš™ï¸ Week 2: MLflow Experiment Tracking + Hyperparameter Tuning
ğŸ§ª MLflow Autologging
Integrated MLflow autologging with train.py

Tracked parameters, metrics, artifacts, and model structure all from code!

ğŸ” Hyperparameter Optimization
Tuned RandomForestRegressor with Hyperopt

Defined a search_space for depth, n_estimators, etc.

Logged top n runs and evaluated them

ğŸ Model Registry
Promoted the best model to the MLflow Model Registry

Validated the model on March 2023 test data â€” best test RMSE: 5.59

Registered model: nyc-taxi-rf-model

ğŸ’¡ Key Takeaways
âœ… Structure matters â€” reusable code and clear folders saved tons of time
âœ… Outliers skew everything â€” especially for linear models
âœ… MLflow autologging is powerful â€” no more tracking metrics manually
âœ… Experiment tracking + registry = MLOps foundation
